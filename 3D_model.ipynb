{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D (Depthwise 2D) model training\n",
    "I'm going to try working with the 3D images and run them through a basic Conv3D model, see what happens. I'm going to be using the resized data. I found this convolution function called depthwise2D which essentially takes the depth array as a lot of channels in the data.\n",
    "Model name: conv-depthwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writeup of the different model trials:\n",
    "conv-depthwise-0: Basic depthwise model, depthwiseconv2d: kernel_size=32, strides=(2,2), padding='same', global pooling, one hidden layer of size 40, batch_size=10, epochs=10 - training accuracy = 36.84%, best validation acc = 40.74%\n",
    "\n",
    "conv-depthwise-1: Basic depthwise model, depthwiseconv2d: kernel_size=32, strides=(2,2), padding='same', global pooling, one hidden layer of size 40, batch_size=5, epochs=10 - best training accuracy = 36.84%, best val acc = 41.36%\n",
    "\n",
    "conv-depthwise-2: Changed strides to (1,1). Changed padding to 'valid'. Changed learning rate to 0.005, from 0.05 in earlier iterations. Trying on reduced epochs (5) as in the past two iterations the accuracy plateaued by the first or second iteration. Best training accuracy = 36.84%, val acc = 40.74%\n",
    "\n",
    "conv-depthwise-3: New data! (512, 512, 24) data shape, model - added bigger DNN (1024 -> 512 -> 5), added second layer of Depthwise Convolution with strides=(1,1)\n",
    "\n",
    "conv-depthwise-4: Added two more convolutions of kernel size 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/manual_conv/X_train_full.npy')\n",
    "y_train = np.load('data/manual_conv/y_train_full.npy')\n",
    "X_test = np.load('data/manual_conv/X_test_full.npy')\n",
    "y_test = np.load('data/manual_conv/y_test_full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 512, 512, 24) (34, 512, 512, 24) (132, 5) (34, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"data/models/conv-depthwise-5-weights-improvement-{epoch:02d}-{acc:.2f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512, 512, 24)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 481, 481, 24)      24600     \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 225, 225, 24)      24600     \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_3 (Depthwis (None, 162, 162, 24)      98328     \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_4 (Depthwis (None, 50, 50, 24)        98328     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_1 (Dense)       (None, 1024)              25600     \n",
      "_________________________________________________________________\n",
      "hidden_layer_2 (Dense)       (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "softmax_layer (Dense)        (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 798,821\n",
      "Trainable params: 798,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers as l\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def create_model():\n",
    "    input_img = l.Input(shape=(512, 512, 24))\n",
    "    x = l.DepthwiseConv2D(kernel_size=32, strides=(1,1), padding='valid')(input_img)\n",
    "    x = l.DepthwiseConv2D(kernel_size=32, strides=(2,2), padding='valid')(x)\n",
    "    \n",
    "    x = l.DepthwiseConv2D(kernel_size=64, strides=(1,1), padding='valid')(x)\n",
    "    x = l.DepthwiseConv2D(kernel_size=64, strides=(2,2), padding='valid')(x)\n",
    "    x = l.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = l.Dense(1024, activation='relu', name='hidden_layer_1')(x)\n",
    "    x = l.Dense(512, activation='relu', name='hidden_layer_2')(x)\n",
    "    output = l.Dense(5, activation='softmax', name='softmax_layer')(x)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_depthwise(X=X_train, y=y_train, X_test=X_test, y_test=y_test, batch_size=10, epochs=10, verbose=1, path=checkpoint_path):\n",
    "    model = create_model()\n",
    "    rmsprop = keras.optimizers.RMSprop(lr=0.005)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # checkpointing - saving in case something goes wrong\n",
    "    filepath= path\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    model.fit(X, y, batch_size=batch_size, epochs=epochs, callbacks=callbacks_list, verbose=verbose)\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "create_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "132/132 [==============================] - 206s 2s/step - loss: 1.5148 - acc: 0.3636\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.36364, saving model to data/models/conv-depthwise-5-weights-improvement-01-0.36.hdf5\n",
      "Epoch 2/5\n",
      "132/132 [==============================] - 201s 2s/step - loss: 2.4243 - acc: 0.4394\n",
      "\n",
      "Epoch 00002: acc improved from 0.36364 to 0.43939, saving model to data/models/conv-depthwise-5-weights-improvement-02-0.44.hdf5\n",
      "Epoch 3/5\n",
      "132/132 [==============================] - 201s 2s/step - loss: 2.4790 - acc: 0.3712\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.43939\n",
      "Epoch 4/5\n",
      "132/132 [==============================] - 204s 2s/step - loss: 1.8543 - acc: 0.4545\n",
      "\n",
      "Epoch 00004: acc improved from 0.43939 to 0.45455, saving model to data/models/conv-depthwise-5-weights-improvement-04-0.45.hdf5\n",
      "Epoch 5/5\n",
      "120/132 [==========================>...] - ETA: 18s - loss: 1.4677 - acc: 0.3167"
     ]
    }
   ],
   "source": [
    "model = train(batch_size=10, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.612279069774291\n",
      "Test accuracy: 0.38235294117647056\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]) # want the accuracy score to be 0.9998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('data/models/conv-depthwise-4-best-model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm checking the best validation accuracy model and it's testing accuracy\n",
    "model2 = create_model()\n",
    "model2.load_weights(\"data/models/conv-depthwise-4-weights-improvement-02-0.48.hdf5\")\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.2807262715171366\n",
      "Test accuracy: 0.38235294117647056\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]) # want the accuracy score to be 0.9998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-View CNN\n",
    "Trying to see if I can implement a multi-view cnn in Keras, as described here: http://vis-www.cs.umass.edu/mvcnn/.\n",
    "Right now our best accuracy is around 37.8%, with means data (we're able to get 37.8% both on the GDrive and here, though gdrive is a lot faster)\n",
    "\n",
    "Model name:\n",
    "conv-multiview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writeup:\n",
    "conv-multiview-0: Standard multiview cnn, separate 'towers' that did convolution and then global pooling, which are then concatenated and pushed into a deep network. Test acc- 36.84%, best val acc- 40.74% big whoop\n",
    "\n",
    "conv-multiview-1: Made towers more complex with two Convolution layers split by Batch Normalization. \n",
    "\n",
    "conv-multiview-2: multiple conv layers per tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/manual_conv/X_train.npy')\n",
    "y_train = np.load('data/manual_conv/y_train.npy')\n",
    "X_test = np.load('data/manual_conv/X_test.npy')\n",
    "y_test = np.load('data/manual_conv/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 256, 256, 39) (19, 256, 256, 39) (162, 5) (19, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"data/models/conv-multiview-2-weights-improvement-{epoch:02d}-{acc:.2f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_0 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_25 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_37 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 256, 256, 32) 320         input_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 256, 256, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 256, 256, 32) 320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 256, 256, 32) 320         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 256, 256, 32) 320         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 256, 256, 32) 320         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 256, 256, 32) 320         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 256, 256, 32) 320         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 256, 256, 32) 320         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 256, 256, 32) 320         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 256, 256, 32) 320         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 256, 256, 32) 320         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 256, 256, 32) 320         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 256, 256, 32) 320         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 256, 256, 32) 320         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 256, 256, 32) 320         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 256, 256, 32) 320         input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 256, 256, 32) 320         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 256, 256, 32) 320         input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 256, 256, 32) 320         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 256, 256, 32) 320         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 256, 256, 32) 320         input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 256, 256, 32) 320         input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 256, 256, 32) 320         input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 256, 256, 32) 320         input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 256, 256, 32) 320         input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 256, 256, 32) 320         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 256, 256, 32) 320         input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 256, 256, 32) 320         input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 256, 256, 32) 320         input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 256, 256, 32) 320         input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 256, 256, 32) 320         input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 256, 256, 32) 320         input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 256, 256, 32) 320         input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 256, 256, 32) 320         input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 256, 256, 32) 320         input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 256, 256, 32) 320         input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 256, 256, 32) 320         input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 256, 256, 32) 320         input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 256, 256, 32) 128         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 256, 256, 32) 128         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 256, 256, 32) 128         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 256, 256, 32) 128         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 256, 256, 32) 128         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 256, 256, 32) 128         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 256, 256, 32) 128         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 256, 256, 32) 128         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 256, 256, 32) 128         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 256, 256, 32) 128         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 256, 256, 32) 128         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 256, 256, 32) 128         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 256, 256, 32) 128         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 256, 256, 32) 128         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 256, 256, 32) 128         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 256, 256, 32) 128         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 256, 256, 32) 128         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 256, 256, 32) 128         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 256, 256, 32) 128         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 256, 256, 32) 128         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 256, 256, 32) 128         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 256, 256, 32) 128         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 256, 256, 32) 128         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 256, 256, 32) 128         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 256, 256, 32) 128         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 256, 256, 32) 128         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 256, 256, 32) 128         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 256, 256, 32) 128         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 256, 256, 32) 128         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 256, 256, 32) 128         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 256, 256, 32) 128         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 256, 256, 32) 128         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 256, 256, 32) 128         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 256, 256, 32) 128         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 256, 256, 32) 128         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 256, 256, 32) 128         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 256, 256, 32) 128         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 256, 256, 32) 128         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 256, 256, 32) 128         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 124 0           batch_normalization_79[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_81[0][0]     \n",
      "                                                                 batch_normalization_82[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_84[0][0]     \n",
      "                                                                 batch_normalization_85[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_87[0][0]     \n",
      "                                                                 batch_normalization_88[0][0]     \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "                                                                 batch_normalization_90[0][0]     \n",
      "                                                                 batch_normalization_91[0][0]     \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "                                                                 batch_normalization_93[0][0]     \n",
      "                                                                 batch_normalization_94[0][0]     \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "                                                                 batch_normalization_96[0][0]     \n",
      "                                                                 batch_normalization_97[0][0]     \n",
      "                                                                 batch_normalization_98[0][0]     \n",
      "                                                                 batch_normalization_99[0][0]     \n",
      "                                                                 batch_normalization_100[0][0]    \n",
      "                                                                 batch_normalization_101[0][0]    \n",
      "                                                                 batch_normalization_102[0][0]    \n",
      "                                                                 batch_normalization_103[0][0]    \n",
      "                                                                 batch_normalization_104[0][0]    \n",
      "                                                                 batch_normalization_105[0][0]    \n",
      "                                                                 batch_normalization_106[0][0]    \n",
      "                                                                 batch_normalization_107[0][0]    \n",
      "                                                                 batch_normalization_108[0][0]    \n",
      "                                                                 batch_normalization_109[0][0]    \n",
      "                                                                 batch_normalization_110[0][0]    \n",
      "                                                                 batch_normalization_111[0][0]    \n",
      "                                                                 batch_normalization_112[0][0]    \n",
      "                                                                 batch_normalization_113[0][0]    \n",
      "                                                                 batch_normalization_114[0][0]    \n",
      "                                                                 batch_normalization_115[0][0]    \n",
      "                                                                 batch_normalization_116[0][0]    \n",
      "                                                                 batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 1248)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 40)           49960       global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5)            205         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 67,637\n",
      "Trainable params: 65,141\n",
      "Non-trainable params: 2,496\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers as l\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def create_multiview_model(z_size=39):\n",
    "    inputs_img = [l.Input(shape=(256, 256, 1), name=('input_' + str(i))) for i in range(0, z_size)]\n",
    "    towers = []\n",
    "    for img in inputs_img:\n",
    "        x = l.Conv2D(32, (3, 3), padding='same', activation='relu')(img)\n",
    "        x = l.BatchNormalization()(x)\n",
    "                \n",
    "        towers.append(x)\n",
    "        \n",
    "    x = l.concatenate(towers)\n",
    "    x = l.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = l.Dense(40, activation='relu')(x)\n",
    "    output = l.Dense(5, activation='softmax')(x)\n",
    "    model = Model(inputs=inputs_img, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(X=X_train, y=y_train, batch_size=10, epochs=10, verbose=1, path=checkpoint_path):\n",
    "    model = create_multiview_model()\n",
    "    rmsprop = keras.optimizers.RMSprop(lr=0.005)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # checkpointing - saving in case something goes wrong\n",
    "    filepath= path\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    model.fit(X, y, batch_size=batch_size, epochs=epochs, callbacks=callbacks_list, verbose=verbose)\n",
    "    return model\n",
    "\n",
    "create_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10,1248,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node concatenate_2/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b387cdf18e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m39\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-6214ebaffe59>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, y, batch_size, epochs, verbose, path)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10,1248,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node concatenate_2/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "model = train(X=[X_train[:, :, :, i, np.newaxis] for i in range(0, 39)], y= y_train, batch_size=10, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.5489581823349\n",
      "Test accuracy: 0.3684210479259491\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate([X_test[:, :, :, i, np.newaxis] for i in range(0, 39)], y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]) # want the accuracy score to be 0.9998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation for depthwise Convolution models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.load('data/manual_conv/X_train_full.npy')\n",
    "y_train = np.load('data/manual_conv/y_train_full.npy')\n",
    "X_test = np.load('data/manual_conv/X_test_full.npy')\n",
    "y_test = np.load('data/manual_conv/y_test_full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((166, 512, 512, 24), (166, 5))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.concatenate((X_train, X_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kf = []\n",
    "for i in range(0, y.shape[0]):\n",
    "    y_val = \"0\"*y[i][0] + \"1\"*y[i][1] + \"2a\"*y[i][2] + \"2b\"*y[i][3] + \"3\"*y[i][4]\n",
    "    y_kf.append(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ada513564189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "cv = StratifiedKFold(5)\n",
    "\n",
    "acc = 0\n",
    "j = 1\n",
    "for train, test in cv.split(x, y):\n",
    "    x_train = x[train]\n",
    "    y_train = [y[i] for i in train]\n",
    "    x_test = x[test]\n",
    "    y_test = [y[i] for i in test]\n",
    "    \n",
    "    y_train = pd.get_dummies(y_train)\n",
    "    y_test = pd.get_dummies(y_test)\n",
    "    \n",
    "    loss, accuracy = train_depthwise(x_train, y_train, x_test, y_test, 20, 10, path=\"data/models/conv-depthwise-kfold-0-weights-improvement-{epoch:02d}-{acc:.2f}.hdf5\")\n",
    "    print ('Fold #', j, 'Accuracy', accuracy)\n",
    "    acc+=accuracy\n",
    "    j+=1\n",
    "print(acc/(j-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy levels are similar for this model, but - test losses (categorical crossentropy) are very low compared to other models we've tried so far."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
